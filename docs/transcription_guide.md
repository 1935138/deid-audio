# ğŸ™ï¸ ìŒì„± ì „ì‚¬ ê°€ì´ë“œ

## ê°œìš”

`transcription.py` ëª¨ë“ˆì€ faster-whisperë¥¼ ì‚¬ìš©í•˜ì—¬ ê³ í’ˆì§ˆ ìŒì„± ì „ì‚¬ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

### ì£¼ìš” ê¸°ëŠ¥
- **ë‹¤ì¤‘ ëª¨ë¸ ì§€ì›**: tiny ~ large-v3 ëª¨ë¸ ì„ íƒ
- **ë‹¤êµ­ì–´ ì§€ì›**: í•œêµ­ì–´, ì˜ì–´, ìë™ ê°ì§€
- **GPU/CPU ìë™ ì „í™˜**: ìµœì  ì„±ëŠ¥ ë³´ì¥
- **ì¼ê´„ ì²˜ë¦¬**: ë””ë ‰í† ë¦¬ ë‹¨ìœ„ ì²˜ë¦¬
- **ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„**: ì •ë°€í•œ ì‹œê°„ ì •ë³´

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. ì˜ì¡´ì„± ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

### 2. ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from src.transcription import process_single_file

# ë‹¨ì¼ íŒŒì¼ ì „ì‚¬
process_single_file(
    input_path="audio.wav",
    output_dir="output/transcript",
    model_size="medium",
    language="ko"
)
```

### 3. ëª…ë ¹í–‰ ì‚¬ìš©

```bash
# ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬
python src/transcription.py --single-file audio.wav

# ë””ë ‰í† ë¦¬ ì¼ê´„ ì²˜ë¦¬
python src/transcription.py --input data/audio --output results/

# ê³ ê¸‰ ì„¤ì •
python src/transcription.py \
    --input data/audio \
    --output results/ \
    --model large-v3 \
    --language en \
    --device cuda \
    --verbose
```

## ğŸ“‹ ëª¨ë¸ ì„ íƒ ê°€ì´ë“œ

| ëª¨ë¸ | í¬ê¸° | ì†ë„ | ì •í™•ë„ | ê¶Œì¥ ìš©ë„ |
|------|------|------|--------|-----------|
| `tiny` | 39MB | ğŸš€ğŸš€ğŸš€ | â­â­ | ë¹ ë¥¸ í…ŒìŠ¤íŠ¸, ì‹¤ì‹œê°„ |
| `base` | 74MB | ğŸš€ğŸš€ | â­â­â­ | ì¼ë°˜ ìš©ë„ |
| `small` | 244MB | ğŸš€ | â­â­â­â­ | ê· í˜•ì¡íŒ ì„ íƒ |
| `medium` | 769MB | ğŸŒ | â­â­â­â­â­ | ê¶Œì¥ ê¸°ë³¸ê°’ |
| `large-v2` | 1550MB | ğŸŒğŸŒ | â­â­â­â­â­ | ë†’ì€ ì •í™•ë„ |
| `large-v3` | 1550MB | ğŸŒğŸŒ | â­â­â­â­â­ | ìµœì‹ /ìµœê³  ì„±ëŠ¥ |

## ğŸŒ ì–¸ì–´ ì„¤ì •

### ì§€ì› ì–¸ì–´
- `ko`: í•œêµ­ì–´ (ê¸°ë³¸ê°’)
- `en`: ì˜ì–´
- `ja`: ì¼ë³¸ì–´
- `zh`: ì¤‘êµ­ì–´
- `None`: ìë™ ê°ì§€

### ì–¸ì–´ë³„ ìµœì  ì„¤ì •

```python
# í•œêµ­ì–´ (ê¸°ë³¸)
transcribe_audio(path, language="ko", model_size="medium")

# ì˜ì–´ (ë†’ì€ ì •í™•ë„)
transcribe_audio(path, language="en", model_size="large-v3")

# ë‹¤êµ­ì–´/ë¯¸ì§€ ì–¸ì–´
transcribe_audio(path, language=None, model_size="large-v3")
```

## ğŸ› ï¸ í•¨ìˆ˜ ë ˆí¼ëŸ°ìŠ¤

### `transcribe_audio()`
ê¸°ë³¸ ì „ì‚¬ í•¨ìˆ˜

```python
def transcribe_audio(
    audio_file_path: str,
    model_size: str = "medium",
    output_dir: str = "output/transcript",
    language: Optional[str] = "ko",
    device: Optional[str] = None,
    verbose: bool = True
) -> str
```

### `process_directory()`
ë””ë ‰í† ë¦¬ ì¼ê´„ ì²˜ë¦¬

```python
def process_directory(
    input_dir: str,
    output_dir: str = "output/transcript",
    model_size: str = "medium",
    language: Optional[str] = "ko",
    device: Optional[str] = None,
    audio_extensions: Optional[List[str]] = None
) -> None
```

### `load_whisper_model()`
ëª¨ë¸ ë¡œë”© (ì¬ì‚¬ìš© ìµœì í™”)

```python
def load_whisper_model(
    model_size: str,
    device: Optional[str] = None
) -> WhisperModel
```

## ğŸ¯ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤

### 1. ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
```bash
python src/transcription.py \
    --single-file test.wav \
    --model tiny \
    --output temp/
```

### 2. ê³ í’ˆì§ˆ ì „ì‚¬
```bash
python src/transcription.py \
    --single-file important.wav \
    --model large-v3 \
    --language ko \
    --device cuda
```

### 3. ëŒ€ëŸ‰ ì¼ê´„ ì²˜ë¦¬
```bash
python src/transcription.py \
    --input data/interviews/ \
    --output results/transcripts/ \
    --model medium \
    --language ko
```

### 4. ë‹¤êµ­ì–´ ì²˜ë¦¬
```bash
python src/transcription.py \
    --input data/multilingual/ \
    --output results/auto/ \
    --model large-v3 \
    --language none
```

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

### GPU ì‚¬ìš©
```python
# GPU ê°•ì œ ì‚¬ìš©
transcribe_audio(path, device="cuda")

# CPU ê°•ì œ ì‚¬ìš© (í˜¸í™˜ì„±)
transcribe_audio(path, device="cpu")

# ìë™ ì„ íƒ (ê¶Œì¥)
transcribe_audio(path, device=None)
```

### ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”
```python
# ëª¨ë¸ ì¬ì‚¬ìš©ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ
model = load_whisper_model("medium", "cuda")

for audio_file in audio_files:
    # transcribe_audio_with_model() ì‚¬ìš©
    # ëª¨ë¸ ì¬ë¡œë”© ì—†ì´ ë¹ ë¥¸ ì²˜ë¦¬
    pass
```

### ë©”ëª¨ë¦¬ ê´€ë¦¬
- **ëª¨ë¸ í¬ê¸°**: ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ì— ë§ê²Œ ì„ íƒ
- **ë°°ì¹˜ í¬ê¸°**: ëŒ€ëŸ‰ ì²˜ë¦¬ ì‹œ ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§
- **ì„ì‹œ íŒŒì¼**: ìë™ ì •ë¦¬ë¨

## ğŸ“„ ì¶œë ¥ í˜•ì‹

### JSON êµ¬ì¡°
```json
{
  "source_file": "audio.wav",
  "model_info": "faster-whisper-medium (lang: ko, confidence: 0.95)",
  "processing_time": 12.34,
  "full_transcript": "ì „ì²´ ì „ì‚¬ í…ìŠ¤íŠ¸...",
  "segments": [
    {
      "id": 0,
      "start": 0.0,
      "end": 3.5,
      "text": "ì•ˆë…•í•˜ì„¸ìš”",
      "words": [
        {
          "word": "ì•ˆë…•í•˜ì„¸ìš”",
          "start": 0.0,
          "end": 1.2,
          "is_pii": false
        }
      ]
    }
  ]
}
```

### íŒŒì¼ëª… ê·œì¹™
```
ì›ë³¸íŒŒì¼ëª…_whisper-ëª¨ë¸ëª…_íƒ€ì„ìŠ¤íƒ¬í”„.json

ì˜ˆì‹œ:
interview_20231201_whisper-medium_20231201_143022.json
```

## ğŸ”§ ê³ ê¸‰ ì„¤ì •

### VAD (Voice Activity Detection) ì¡°ì •
```python
# ê¸°ë³¸ VAD ì„¤ì • (ì½”ë“œ ë‚´ë¶€)
vad_parameters = vad.VadOptions(
    threshold=0.3,              # ìŒì„± ê°ì§€ ì„ê³„ê°’
    neg_threshold=0.15,         # ë¬´ìŒ ì„ê³„ê°’
    min_speech_duration_ms=1200, # ìµœì†Œ ìŒì„± ê¸¸ì´
    max_speech_duration_s=30,   # ìµœëŒ€ ìŒì„± ê¸¸ì´
    min_silence_duration_ms=2000, # ìµœì†Œ ë¬´ìŒ ê¸¸ì´
    speech_pad_ms=1000          # ìŒì„± íŒ¨ë”©
)
```

### ë¹” ì„œì¹˜ ì„¤ì •
```python
# ì •í™•ë„ vs ì†ë„ ì¡°ì ˆ
beam_size=5      # ê¸°ë³¸ê°’ (ê· í˜•)
beam_size=1      # ë¹ ë¦„ (ê·¸ë¦¬ë”” ë””ì½”ë”©)
beam_size=10     # ëŠë¦¼ (ë†’ì€ ì •í™•ë„)
```

## ğŸ› ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ì˜¤ë¥˜

**CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±**
```bash
# ë” ì‘ì€ ëª¨ë¸ ì‚¬ìš©
--model medium  # ëŒ€ì‹  small ì‚¬ìš©

# CPU ëª¨ë“œë¡œ ì „í™˜
--device cpu
```

**íŒŒì¼ í˜•ì‹ ì˜¤ë¥˜**
```bash
# ì§€ì› í˜•ì‹ í™•ì¸
--extensions .wav .mp3 .flac

# FFmpeg ì„¤ì¹˜ í•„ìš”í•  ìˆ˜ ìˆìŒ
sudo apt install ffmpeg  # Ubuntu
brew install ffmpeg      # macOS
```

**ì–¸ì–´ ê°ì§€ ì˜¤ë¥˜**
```bash
# ëª…ì‹œì  ì–¸ì–´ ì„¤ì •
--language ko  # í•œêµ­ì–´ ê°•ì œ
--language en  # ì˜ì–´ ê°•ì œ
```

### ë¡œê·¸ í™•ì¸
```bash
# ìƒì„¸ ë¡œê·¸ í™œì„±í™”
--verbose

# ë˜ëŠ” Pythonì—ì„œ
import logging
logging.basicConfig(level=logging.DEBUG)
```

## ğŸ“ˆ ë²¤ì¹˜ë§ˆí¬

### ì„±ëŠ¥ ì°¸ê³  (RTX 3080 ê¸°ì¤€)

| ëª¨ë¸ | 10ë¶„ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì‹œê°„ | GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ |
|------|---------------------|------------------|
| tiny | ~30ì´ˆ | ~1GB |
| base | ~45ì´ˆ | ~1.5GB |
| small | ~1ë¶„ | ~2GB |
| medium | ~2ë¶„ | ~4GB |
| large-v3 | ~4ë¶„ | ~8GB |

### ì •í™•ë„ ì°¸ê³ 

- **í•œêµ­ì–´**: medium ì´ìƒ ê¶Œì¥
- **ì˜ì–´**: small ì´ìƒ ì¶©ë¶„
- **ê¸°ìˆ  ìš©ì–´**: large-v3 ê¶Œì¥
- **ë…¸ì´ì¦ˆ ë§ì€ í™˜ê²½**: large-v3 + ì „ì²˜ë¦¬

## ğŸ”— í†µí•© ì‚¬ìš©

### ì „ì²˜ë¦¬ì™€ ì—°ê³„
```bash
# 1ë‹¨ê³„: ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬
python src/preprocessing.py --input raw/ --output preprocessed/

# 2ë‹¨ê³„: ì „ì‚¬
python src/transcription.py --input preprocessed/ --output transcripts/
```

### íŒŒì´í”„ë¼ì¸ ì˜ˆì‹œ
```python
from src.preprocessing import process_single_file as preprocess
from src.transcription import process_single_file as transcribe

# ì™„ì „í•œ íŒŒì´í”„ë¼ì¸
def full_pipeline(input_audio, output_dir):
    # 1. ì „ì²˜ë¦¬
    preprocessed = preprocess(
        input_audio, 
        f"{output_dir}/preprocessed.wav"
    )
    
    # 2. ì „ì‚¬
    transcript = transcribe(
        preprocessed,
        f"{output_dir}/transcript"
    )
    
    return transcript
```

## ğŸ“š ì°¸ê³  ìë£Œ

- [Faster-Whisper GitHub](https://github.com/guillaumekln/faster-whisper)
- [OpenAI Whisper ë…¼ë¬¸](https://arxiv.org/abs/2212.04356)
- [Whisper ëª¨ë¸ ì¹´ë“œ](https://github.com/openai/whisper/blob/main/model-card.md)
