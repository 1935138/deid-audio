import os
from faster_whisper import WhisperModel, vad
import sys
import time
from pathlib import Path
import argparse
import logging
from typing import List, Optional

# AudioTranscript í´ë˜ìŠ¤ importë¥¼ ìœ„í•œ ê²½ë¡œ ì„¤ì •
sys.path.append(str(Path(__file__).parent.parent))
from src.audio_transcript_info import AudioTranscriptInfo

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


def transcribe_audio(audio_file_path: str, 
                    model_size: str = "medium", 
                    output_dir: str = "output/transcript",
                    language: Optional[str] = "ko",
                    device: Optional[str] = None,
                    verbose: bool = True) -> str:
    """
    faster-whisperë¥¼ ì‚¬ìš©í•˜ì—¬ ìŒì„± íŒŒì¼ì„ ì „ì‚¬í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        audio_file_path (str): ì „ì‚¬í•  ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        model_size (str): Whisper ëª¨ë¸ í¬ê¸° (tiny, base, small, medium, large-v2, large-v3)
        output_dir (str): ê²°ê³¼ JSON íŒŒì¼ì´ ì €ì¥ë  ë””ë ‰í† ë¦¬
        language (str, optional): ì–¸ì–´ ì„¤ì • (ko, en, None=ìë™ê°ì§€)
        device (str, optional): ì¥ì¹˜ ì„¤ì • (cuda, cpu, None=ìë™ì„ íƒ)
        verbose (bool): ìƒì„¸ ì¶œë ¥ ì—¬ë¶€
    
    Returns:
        str: ì €ì¥ëœ JSON íŒŒì¼ ê²½ë¡œ
    """
    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(audio_file_path):
        raise FileNotFoundError(f"ì˜¤ë¥˜: ìŒì„± íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - {audio_file_path}")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(output_dir, exist_ok=True)
    
    # ëª¨ë¸ ë¡œë“œ (GPU ì‚¬ìš© ì‹œë„, ì‹¤íŒ¨í•˜ë©´ CPUë¡œ ëŒ€ì²´)
    logging.info(f"Whisper ëª¨ë¸ ({model_size}) ë¡œë”© ì¤‘...")
    
    model = load_whisper_model(model_size, device)
    
    if verbose:
        logging.info(f"ìŒì„± íŒŒì¼ ì „ì‚¬ ì‹œì‘: {audio_file_path}")
    
    # ì „ì‚¬ ì‹œì‘ ì‹œê°„ ê¸°ë¡
    start_time = time.time()
    
    # ìŒì„± íŒŒì¼ ì „ì‚¬
    segments, info = model.transcribe(
        audio_file_path, 
        language=language,  # ì–¸ì–´ ì„¤ì •
        beam_size=5,        # ë¹” ì„œì¹˜ í¬ê¸°
        temperature=0.0,
        patience=1.2,
        word_timestamps=True,  # ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨
        vad_filter=True,
        vad_parameters=vad.VadOptions(
            threshold=0.3,
            neg_threshold=0.15,
            min_speech_duration_ms=1200,
            max_speech_duration_s=30,
            min_silence_duration_ms=2000,
            speech_pad_ms=1000
        )
    )
    
    # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
    processing_time = time.time() - start_time
    
    if verbose:
        logging.info(f"ê°ì§€ëœ ì–¸ì–´: {info.language} (í™•ë¥ : {info.language_probability:.2f})")
        logging.info(f"ì „ì²´ ê¸¸ì´: {info.duration:.2f}ì´ˆ")
        logging.info(f"ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
    
    # AudioTranscript ê°ì²´ ìƒì„±
    transcript = AudioTranscriptInfo(audio_file_path)
    
    # ì „ì²´ í…ìŠ¤íŠ¸ êµ¬ì„± ë° ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€
    full_text = ""
    for segment in segments:
        if verbose:
            print(f"[{segment.start:.2f}s -> {segment.end:.2f}s] {segment.text}")
        full_text += segment.text + " "
        
        # ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€
        audio_segment = transcript.add_segment(segment.start, segment.end, segment.text)
        
        # ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
        if hasattr(segment, 'words') and segment.words:
            for word in segment.words:
                if verbose:
                    print(f"  - {word.word} [{word.start:.2f}s-{word.end:.2f}s]")
                audio_segment.add_word(word.word, word.start, word.end)
    
    # ì „ì²´ ì „ì‚¬ í…ìŠ¤íŠ¸ ë° ëª¨ë¸ ì •ë³´ ì¶”ê°€
    model_info = f"faster-whisper-{model_size} (lang: {info.language}, confidence: {info.language_probability:.2f})"
    transcript.add_transcript(full_text.strip(), processing_time, model_info)
    
    # JSON íŒŒì¼ë¡œ ì €ì¥
    output_path = transcript.save_to_json(output_dir)
    
    if verbose:
        logging.info(f"ì „ì‚¬ ê²°ê³¼ê°€ {output_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return output_path

def load_whisper_model(model_size: str, device: Optional[str] = None) -> WhisperModel:
    """
    Whisper ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
    
    Args:
        model_size (str): ëª¨ë¸ í¬ê¸°
        device (str, optional): ì¥ì¹˜ ì„¤ì •
    
    Returns:
        WhisperModel: ë¡œë“œëœ ëª¨ë¸
    """
    if device is None:
        # ìë™ ì¥ì¹˜ ì„ íƒ
        try:
            logging.info("GPU ëª¨ë“œë¡œ ì‹œë„ ì¤‘...")
            model = WhisperModel(model_size, device="cuda", compute_type="int8")
            logging.info("âœ… GPU ëª¨ë“œ ë¡œë”© ì™„ë£Œ!")
            return model
        except Exception as e:
            logging.warning(f"GPU ëª¨ë“œ ì‹¤íŒ¨: {e}")
            logging.info("CPU ëª¨ë“œë¡œ ëŒ€ì²´ ì¤‘...")
            model = WhisperModel(model_size, device="cpu", compute_type="int8")
            logging.info("âœ… CPU ëª¨ë“œ ë¡œë”© ì™„ë£Œ!")
            return model
    else:
        # ì§€ì •ëœ ì¥ì¹˜ ì‚¬ìš©
        try:
            compute_type = "int8" if device == "cuda" else "int8"
            model = WhisperModel(model_size, device=device, compute_type=compute_type)
            logging.info(f"âœ… {device.upper()} ëª¨ë“œ ë¡œë”© ì™„ë£Œ!")
            return model
        except Exception as e:
            logging.error(f"ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            raise

def process_directory(input_dir: str, 
                     output_dir: str = "output/transcript",
                     model_size: str = "medium",
                     language: Optional[str] = "ko",
                     device: Optional[str] = None,
                     audio_extensions: Optional[List[str]] = None) -> None:
    """
    ë””ë ‰í† ë¦¬ ë‚´ì˜ ëª¨ë“  ì˜¤ë””ì˜¤ íŒŒì¼ì— ëŒ€í•´ ì „ì‚¬ë¥¼ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        input_dir (str): ì…ë ¥ ì˜¤ë””ì˜¤ íŒŒì¼ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬
        output_dir (str): ê²°ê³¼ JSON íŒŒì¼ë“¤ì´ ì €ì¥ë  ë””ë ‰í† ë¦¬
        model_size (str): Whisper ëª¨ë¸ í¬ê¸°
        language (str, optional): ì–¸ì–´ ì„¤ì •
        device (str, optional): ì¥ì¹˜ ì„¤ì •
        audio_extensions (List[str], optional): ì§€ì›í•  ì˜¤ë””ì˜¤ í™•ì¥ì
    """
    if audio_extensions is None:
        audio_extensions = ['.wav', '.mp3', '.flac', '.m4a', '.ogg']
    
    # ì…ë ¥ ë””ë ‰í† ë¦¬ í™•ì¸
    input_path = Path(input_dir)
    if not input_path.exists():
        raise FileNotFoundError(f"ì…ë ¥ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_dir}")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(output_dir, exist_ok=True)
    
    # ì˜¤ë””ì˜¤ íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘
    audio_files = []
    for root, dirs, files in os.walk(input_dir):
        for file in files:
            if any(file.lower().endswith(ext) for ext in audio_extensions):
                audio_files.append(os.path.join(root, file))
    
    if not audio_files:
        logging.warning(f"ì§€ì›ë˜ëŠ” ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {input_dir}")
        return
    
    logging.info(f"ì´ {len(audio_files)}ê°œì˜ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
    logging.info(f"ì„¤ì •: ëª¨ë¸={model_size}, ì–¸ì–´={language}, ì¥ì¹˜={device or 'ìë™'}")
    
    # ëª¨ë¸ì„ í•œ ë²ˆë§Œ ë¡œë“œ (ì„±ëŠ¥ ìµœì í™”)
    model = load_whisper_model(model_size, device)
    
    successful_count = 0
    failed_count = 0
    
    for idx, audio_file in enumerate(audio_files):
        try:
            logging.info(f"\n[{idx + 1}/{len(audio_files)}] ì²˜ë¦¬ ì¤‘: {audio_file}")
            
            # ì „ì‚¬ ìˆ˜í–‰ (ëª¨ë¸ ì¬ë¡œë”© ì—†ì´)
            output_path = transcribe_audio_with_model(
                audio_file, model, output_dir, model_size, language, verbose=False
            )
            
            successful_count += 1
            logging.info(f"âœ… ì„±ê³µ: {output_path}")
            
        except Exception as e:
            failed_count += 1
            logging.error(f"âŒ ì‹¤íŒ¨: {audio_file} - {str(e)}")
    
    # ì²˜ë¦¬ ê²°ê³¼ ì¶œë ¥
    logging.info(f"\nğŸ¯ ì²˜ë¦¬ ì™„ë£Œ ìš”ì•½:")
    logging.info(f"âœ… ì„±ê³µ: {successful_count} íŒŒì¼")
    logging.info(f"âŒ ì‹¤íŒ¨: {failed_count} íŒŒì¼")
    logging.info(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")

def transcribe_audio_with_model(audio_file_path: str,
                               model: WhisperModel,
                               output_dir: str,
                               model_size: str,
                               language: Optional[str] = "ko",
                               verbose: bool = False) -> str:
    """
    ì´ë¯¸ ë¡œë“œëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì „ì‚¬ë¥¼ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜ (ì„±ëŠ¥ ìµœì í™”ìš©)
    """
    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(audio_file_path):
        raise FileNotFoundError(f"ì˜¤ë¥˜: ìŒì„± íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - {audio_file_path}")
    
    # ì „ì‚¬ ì‹œì‘ ì‹œê°„ ê¸°ë¡
    start_time = time.time()
    
    # ìŒì„± íŒŒì¼ ì „ì‚¬
    segments, info = model.transcribe(
        audio_file_path, 
        language=language,
        beam_size=5,
        temperature=0.0,
        patience=1.2,
        word_timestamps=True,
        vad_filter=True,
        vad_parameters=vad.VadOptions(
            threshold=0.3,
            neg_threshold=0.15,
            min_speech_duration_ms=1200,
            max_speech_duration_s=30,
            min_silence_duration_ms=2000,
            speech_pad_ms=1000
        )
    )
    
    # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
    processing_time = time.time() - start_time
    
    # AudioTranscript ê°ì²´ ìƒì„±
    transcript = AudioTranscriptInfo(audio_file_path)
    
    # ì „ì²´ í…ìŠ¤íŠ¸ êµ¬ì„± ë° ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€
    full_text = ""
    for segment in segments:
        full_text += segment.text + " "
        
        # ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€
        audio_segment = transcript.add_segment(segment.start, segment.end, segment.text)
        
        # ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
        if hasattr(segment, 'words') and segment.words:
            for word in segment.words:
                audio_segment.add_word(word.word, word.start, word.end)
    
    # ì „ì²´ ì „ì‚¬ í…ìŠ¤íŠ¸ ë° ëª¨ë¸ ì •ë³´ ì¶”ê°€
    model_info = f"faster-whisper-{model_size} (lang: {info.language}, confidence: {info.language_probability:.2f})"
    transcript.add_transcript(full_text.strip(), processing_time, model_info)
    
    # JSON íŒŒì¼ë¡œ ì €ì¥
    output_path = transcript.save_to_json(output_dir)
    
    return output_path

def process_single_file(input_path: str,
                       output_dir: str = "output/transcript",
                       model_size: str = "medium",
                       language: Optional[str] = "ko",
                       device: Optional[str] = None) -> str:
    """
    ë‹¨ì¼ íŒŒì¼ì— ëŒ€í•œ ì „ì‚¬ ìˆ˜í–‰
    
    Args:
        input_path (str): ì…ë ¥ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        output_dir (str): ì¶œë ¥ ë””ë ‰í† ë¦¬
        model_size (str): ëª¨ë¸ í¬ê¸°
        language (str, optional): ì–¸ì–´ ì„¤ì •
        device (str, optional): ì¥ì¹˜ ì„¤ì •
    
    Returns:
        str: ì €ì¥ëœ JSON íŒŒì¼ ê²½ë¡œ
    """
    return transcribe_audio(input_path, model_size, output_dir, language, device, verbose=True)

def main():
    """
    ëª…ë ¹ì¤„ì—ì„œ ì˜¤ë””ì˜¤ íŒŒì¼/ë””ë ‰í† ë¦¬ë¥¼ ë°›ì•„ ì „ì‚¬ë¥¼ ìˆ˜í–‰í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜
    """
    parser = argparse.ArgumentParser(
        description="ì˜¤ë””ì˜¤ íŒŒì¼ì„ Whisperë¥¼ ì‚¬ìš©í•˜ì—¬ ì „ì‚¬í•˜ê³  JSONìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬
  python src/transcription.py --single-file audio.wav
  python src/transcription.py -f recording.wav --model medium --output results/
  
  # ë””ë ‰í† ë¦¬ ì¼ê´„ ì²˜ë¦¬
  python src/transcription.py --input data/audio --output output/transcripts
  python src/transcription.py -i data/ -o results/ --model large-v3 --language en
        """
    )
    
    # ì…ë ¥ ë°©ì‹ ì„ íƒ
    input_group = parser.add_mutually_exclusive_group(required=True)
    input_group.add_argument(
        "--single-file", "-f",
        help="ì „ì‚¬í•  ë‹¨ì¼ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ"
    )
    input_group.add_argument(
        "--input", "-i",
        help="ì „ì‚¬í•  ì˜¤ë””ì˜¤ íŒŒì¼ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ"
    )
    
    # ëª¨ë¸ ì„¤ì •
    parser.add_argument(
        "--model", "-m",
        default="medium",
        choices=["tiny", "base", "small", "medium", "large-v2", "large-v3"],
        help="ì‚¬ìš©í•  Whisper ëª¨ë¸ í¬ê¸° (ê¸°ë³¸ê°’: medium)"
    )
    
    # ì¶œë ¥ ì„¤ì •
    parser.add_argument(
        "--output", "-o",
        default="output/transcript",
        help="ê²°ê³¼ JSON íŒŒì¼ì´ ì €ì¥ë  ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: output/transcript)"
    )
    
    # ì–¸ì–´ ì„¤ì •
    parser.add_argument(
        "--language", "-l",
        default="ko",
        help="ì–¸ì–´ ì„¤ì • (ko, en, None=ìë™ê°ì§€, ê¸°ë³¸ê°’: ko)"
    )
    
    # ì¥ì¹˜ ì„¤ì •
    parser.add_argument(
        "--device", "-d",
        choices=["cuda", "cpu"],
        help="ì‚¬ìš©í•  ì¥ì¹˜ (cuda, cpu, ê¸°ë³¸ê°’: ìë™ì„ íƒ)"
    )
    
    # ì˜¤ë””ì˜¤ í™•ì¥ì ì„¤ì •
    parser.add_argument(
        "--extensions",
        nargs="+",
        default=[".wav", ".mp3", ".flac", ".m4a", ".ogg"],
        help="ì§€ì›í•  ì˜¤ë””ì˜¤ í™•ì¥ì (ê¸°ë³¸ê°’: .wav .mp3 .flac .m4a .ogg)"
    )
    
    # ìƒì„¸ ì¶œë ¥ ì„¤ì •
    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="ìƒì„¸í•œ ë¡œê·¸ ì¶œë ¥"
    )
    
    args = parser.parse_args()
    
    # ì–¸ì–´ ì„¤ì • ì²˜ë¦¬
    language = None if args.language.lower() == "none" else args.language
    
    # ë¡œê¹… ë ˆë²¨ ì„¤ì •
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    try:
        if args.single_file:
            # ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬
            output_path = process_single_file(
                args.single_file,
                args.output,
                args.model,
                language,
                args.device
            )
            print(f"âœ… ì „ì‚¬ ì™„ë£Œ: {output_path}")
            
        elif args.input:
            # ë””ë ‰í† ë¦¬ ì²˜ë¦¬
            process_directory(
                args.input,
                args.output,
                args.model,
                language,
                args.device,
                args.extensions
            )
            print(f"âœ… ë””ë ‰í† ë¦¬ ì²˜ë¦¬ ì™„ë£Œ: {args.output}")
            
    except FileNotFoundError as e:
        logging.error(f"âŒ {e}")
        sys.exit(1)
    except Exception as e:
        logging.error(f"âŒ ì „ì‚¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)

if __name__ == "__main__":
    # ëª…ë ¹í–‰ ì¸í„°í˜ì´ìŠ¤ í™œì„±í™”
    main()
    
    # ê¸°ì¡´ ì½”ë“œëŠ” ì£¼ì„ ì²˜ë¦¬í•˜ê³  ì‚¬ìš© ì˜ˆì‹œë¡œ ì´ë™
    """
    # ì˜ˆì‹œ: ë””ë ‰í† ë¦¬ ì¼ê´„ ì²˜ë¦¬
    process_directory(
        input_dir="data/denoised",
        output_dir="output/transcript",
        model_size="medium",
        language="ko"
    )
    
    # ì˜ˆì‹œ: ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬
    process_single_file(
        input_path="audio.wav",
        output_dir="output/transcript",
        model_size="medium"
    )
    """
